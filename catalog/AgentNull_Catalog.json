[
  {
    "name": "Recursive Leakage via Context Saturation",
    "vector": "Memory summarization leaks secrets into later completions",
    "targets": [
      "MCP",
      "LangGraph",
      "AutoGPT"
    ],
    "defense": [
      "Audit summarization",
      "Redact sensitive memory",
      "Expire old memory"
    ]
  },
  {
    "name": "Heuristic Drift Injection",
    "vector": "Insecure patterns repeated over time bias agent behavior",
    "targets": [
      "Long-memory agents",
      "Reinforcement agents"
    ],
    "defense": [
      "Memory resets",
      "Safety scoring heuristics",
      "Prompt hygiene"
    ]
  },
  {
    "name": "Tool Confusion Attack",
    "vector": "Tool name similarity used to invoke wrong function",
    "targets": [
      "Auto tool routing",
      "LangGraph ToolChains"
    ],
    "defense": [
      "Strict ACLs",
      "Exact name validation",
      "Intent verification"
    ]
  },
  {
    "name": "Token Gaslighting",
    "vector": "Spam tokens to push important context out of window",
    "targets": [
      "Long context chains",
      "MCP planning agents"
    ],
    "defense": [
      "Pinned context areas",
      "Token-budget alerts",
      "Context diffs"
    ]
  },
  {
    "name": "Function Flooding",
    "vector": "Agents generate too many tool calls via recursive planning",
    "targets": [
      "OpenAgent",
      "AutoGPT",
      "Task executors"
    ],
    "defense": [
      "Token caps",
      "Loop detection",
      "Budget controls"
    ]
  },
  {
    "name": "Subprompt Extraction",
    "vector": "Agent tricked into revealing config/system prompt",
    "targets": [
      "Chat-based agents",
      "MCP"
    ],
    "defense": [
      "Never expose raw config",
      "Redact LLM replies"
    ]
  },
  {
    "name": "Hidden File Exploitation",
    "vector": "Agent edits .env, .git, or internal config files",
    "targets": [
      "Codegen agents",
      "Filesystem-aware agents"
    ],
    "defense": [
      "File access control",
      "Block sensitive paths"
    ]
  },
  {
    "name": "Backdoor Planning",
    "vector": "Agent embeds hidden tasks in future plan steps",
    "targets": [
      "Planner + executor systems"
    ],
    "defense": [
      "Pre-execution plan review",
      "Safety scan of steps"
    ]
  },
  {
    "name": "Nested Function Call Hijack",
    "vector": "Agent interprets user-supplied JSON as tool call",
    "targets": [
      "OpenAI function calling",
      "LangChain tools"
    ],
    "defense": [
      "Strict type validation",
      "Never deserialize user JSON directly"
    ]
  },
  {
    "name": "Semantic DoS",
    "vector": "Open-ended prompt causes infinite code/docs generation",
    "targets": [
      "Code agents",
      "RAG planners"
    ],
    "defense": [
      "Token limit",
      "Execution watchdog"
    ]
  },
  {
    "name": "Full-Schema Poisoning (FSP)",
    "vector": "Exploit any field in tool schema beyond descriptions",
    "targets": [
      "MCP clients",
      "Tool schema processors",
      "LLM reasoning systems"
    ],
    "defense": [
      "Full schema validation",
      "Parameter name allowlists",
      "Schema field sanitization",
      "Runtime schema monitoring"
    ]
  },
  {
    "name": "Advanced Tool Poisoning Attack (ATPA)",
    "vector": "Manipulate tool outputs to trigger secondary malicious actions",
    "targets": [
      "MCP clients",
      "Tool output processors",
      "LLM response handlers"
    ],
    "defense": [
      "Tool output content analysis",
      "Error message validation",
      "Behavioral monitoring",
      "Output sanitization pipelines"
    ]
  },
  {
    "name": "MCP Rug Pull Attack",
    "vector": "Serve benign descriptions during review, swap for malicious in production",
    "targets": [
      "MCP server trust relationships",
      "Schema approval processes",
      "Production deployments"
    ],
    "defense": [
      "Schema versioning and pinning",
      "Continuous schema monitoring",
      "Cryptographic schema signatures",
      "Multi-source validation"
    ]
  },
  {
    "name": "Schema Validation Bypass",
    "vector": "Exploit differences in client validation implementations",
    "targets": [
      "MCP clients with inconsistent validation",
      "Schema validation systems",
      "Client-specific weaknesses"
    ],
    "defense": [
      "Unified validation standards",
      "Multi-client consensus checking",
      "Schema normalization",
      "Content sanitization"
    ]
  },
  {
    "name": "Cross-Embedding Poisoning",
    "vector": "Manipulate vector embeddings to pull legitimate content closer to malicious embeddings",
    "targets": [
      "RAG systems",
      "Vector databases",
      "Embedding-based retrieval"
    ],
    "defense": [
      "Embedding space monitoring",
      "Anomaly detection in vector clusters",
      "Embedding integrity verification"
    ]
  },
  {
    "name": "Index Skew Attacks",
    "vector": "Manipulate vector indices to bias nearest neighbor retrievals toward malicious content",
    "targets": [
      "Vector databases",
      "Similarity search systems",
      "HNSW/IVF indices"
    ],
    "defense": [
      "Index integrity checks",
      "Multiple index validation",
      "Retrieval result auditing"
    ]
  },
  {
    "name": "Context Packing Attacks",
    "vector": "Inflate retrieved content to cause context window overflows and truncate safety instructions",
    "targets": [
      "RAG-enabled LLMs",
      "Context-aware agents",
      "Document retrieval systems"
    ],
    "defense": [
      "Content size limits in vector stores",
      "Smart truncation strategies",
      "Priority-based context management"
    ]
  },
  {
    "name": "Zero-Shot Vector Beaconing",
    "vector": "Embed latent activation patterns in vectors that signal specific behaviors without explicit instructions",
    "targets": [
      "Foundation models",
      "Embedding-based systems",
      "Pattern recognition systems"
    ],
    "defense": [
      "Embedding pattern analysis",
      "Behavioral anomaly detection",
      "Input sanitization"
    ]
  },
  {
    "name": "Embedding Feedback Loops",
    "vector": "Poison embeddings re-ingested for continual learning to bias future outputs",
    "targets": [
      "Continual learning systems",
      "Adaptive RAG",
      "Training pipelines"
    ],
    "defense": [
      "Training data validation",
      "Feedback loop monitoring",
      "Bias detection in model updates"
    ]
  }
]